# åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ èµ„æºåˆ†é…
## ç»„ä¼šæ±‡æŠ¥

---

## ç›®å½•

1. ç ”ç©¶èƒŒæ™¯ä¸ç›®æ ‡
2. æŠ€æœ¯æ–¹æ¡ˆ
3. ç³»ç»Ÿæ¶æ„
4. å®ç°ç»†èŠ‚
5. å½“å‰è¿›å±•
6. é‡åˆ°çš„é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
7. ä¸‹ä¸€æ­¥è®¡åˆ’

---

## 1. ç ”ç©¶èƒŒæ™¯ä¸ç›®æ ‡

### 1.1 ç ”ç©¶èƒŒæ™¯

- **å¤šUAVé€šä¿¡åœºæ™¯**ï¼š6ä¸ªUAVåœ¨25mÃ—25måŒºåŸŸå†…è¿›è¡Œè¯­ä¹‰é€šä¿¡
- **èµ„æºåˆ†é…é—®é¢˜**ï¼š
  - èµ„æºå—ï¼ˆRBï¼‰é€‰æ‹©ï¼š10ä¸ªå¯ç”¨RB
  - ä¼ è¾“åŠŸç‡æ§åˆ¶ï¼šè¿ç»­åŠ¨ä½œç©ºé—´
  - è¯­ä¹‰å‹ç¼©æ¯”ï¼ˆÏï¼‰ï¼š0-1ä¹‹é—´çš„è¿ç»­å€¼
- **æŒ‘æˆ˜**ï¼š
  - å¤šæ™ºèƒ½ä½“åä½œ
  - åŠ¨æ€ç¯å¢ƒ
  - éƒ¨åˆ†å¯è§‚æµ‹æ€§

### 1.2 ç ”ç©¶ç›®æ ‡

- å®ç°åŸºäº**å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰**çš„å¤šæ™ºèƒ½ä½“PPOç®—æ³•
- æå‡å¤šUAVåä½œæ•ˆç‡
- ä¼˜åŒ–è¯­ä¹‰é€šä¿¡çš„èƒ½æ•ˆï¼ˆSemantic-EEï¼‰

---

## 2. æŠ€æœ¯æ–¹æ¡ˆ

### 2.1 ç®—æ³•æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¤šæ™ºèƒ½ä½“ç¯å¢ƒ (6 UAVs)                    â”‚
â”‚  - çŠ¶æ€ï¼šCSIã€ä½ç½®ã€æˆåŠŸæ ‡å¿—              â”‚
â”‚  - åŠ¨ä½œï¼šRBã€åŠŸç‡ã€å‹ç¼©æ¯”                 â”‚
â”‚  - å¥–åŠ±ï¼šSemantic-EE + æƒ©ç½š              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å›¾æ³¨æ„åŠ›ç½‘ç»œ (GAT)                      â”‚
â”‚  - èŠ‚ç‚¹ç‰¹å¾ï¼šCSIã€ä½ç½®ã€çŠ¶æ€              â”‚
â”‚  - é‚»æ¥çŸ©é˜µï¼šåŸºäºé€šä¿¡è·ç¦»                 â”‚
â”‚  - å¤šå¤´æ³¨æ„åŠ›ï¼š4ä¸ªæ³¨æ„åŠ›å¤´               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PPOç®—æ³• (Actor-Critic)                 â”‚
â”‚  - Actorï¼š3ä¸ªè¾“å‡ºå¤´ï¼ˆåŠŸç‡ã€RBã€å‹ç¼©æ¯”ï¼‰   â”‚
â”‚  - Criticï¼šå€¼å‡½æ•°ä¼°è®¡                    â”‚
â”‚  - è”é‚¦å­¦ä¹ ï¼šå‚æ•°å¹³å‡                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å…³é”®æŠ€æœ¯

- **å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰**
  - æ˜¾å¼å»ºæ¨¡UAVä¹‹é—´çš„é€šä¿¡å…³ç³»
  - å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆ4ä¸ªå¤´ï¼‰
  - æ®‹å·®è¿æ¥æå‡è®­ç»ƒç¨³å®šæ€§

- **å¤šæ™ºèƒ½ä½“PPO**
  - æ¯ä¸ªUAVç‹¬ç«‹Actor-Criticç½‘ç»œ
  - å…±äº«ç»éªŒå›æ”¾
  - è”é‚¦å­¦ä¹ å‚æ•°èšåˆ

- **è¯­ä¹‰é€šä¿¡**
  - è¯­ä¹‰å‡†ç¡®åº¦ï¼š`A(Ï, SINR) = A_max * (1 - exp(-Î²*Ï)) * log(1+SINR)`
  - è¯­ä¹‰èƒ½æ•ˆï¼š`Semantic-EE = A / (æ€»åŠŸç‡)`

---

## 3. ç³»ç»Ÿæ¶æ„

### 3.1 ç½‘ç»œç»“æ„

#### GATç¼–ç å™¨
```
è¾“å…¥: [batch, n_veh, node_feature_dim]
  â†“
GAT Layer 1: [n_veh, hidden_1] Ã— 4 heads
  â†“ (æ®‹å·®è¿æ¥)
GAT Layer 2: [n_veh, hidden_2] Ã— 4 heads
  â†“ (æ®‹å·®è¿æ¥)
GAT Layer 3: [n_veh, hidden_3] Ã— 4 heads
  â†“
èŠ‚ç‚¹åµŒå…¥: [n_veh, hidden_3 Ã— 4]
```

#### Actorç½‘ç»œ
```
èŠ‚ç‚¹åµŒå…¥ â†’ æŠ•å½±å±‚ â†’ Actor Head
  â”œâ”€ Power Head: Normalåˆ†å¸ƒ (Î¼, Ïƒ)
  â”œâ”€ RB Head: Categoricalåˆ†å¸ƒ
  â””â”€ Rho Head: Betaåˆ†å¸ƒ (Î±, Î²)
```

#### Criticç½‘ç»œ
```
èŠ‚ç‚¹åµŒå…¥ â†’ æŠ•å½±å±‚ â†’ å€¼å‡½æ•°
è¾“å‡º: [batch, n_veh] (æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹çš„å€¼ä¼°è®¡)
```

### 3.2 èŠ‚ç‚¹ç‰¹å¾è®¾è®¡

| ç‰¹å¾ç±»å‹ | ç»´åº¦ | è¯´æ˜ |
|---------|------|------|
| CSIå¿«è¡°è½ | n_RB | æ¯ä¸ªRBçš„ä¿¡é“çŠ¶æ€ |
| CSIæ…¢è¡°è½ | n_RB | è·¯å¾„æŸè€—å’Œé˜´å½± |
| ä½ç½®ä¿¡æ¯ | 3 | (x, y, z)åæ ‡ |
| æˆåŠŸæ ‡å¿— | 1 | ä¸Šæ¬¡ä¼ è¾“æ˜¯å¦æˆåŠŸ |
| Episodeè¿›åº¦ | 1 | å½“å‰episodeè¿›åº¦ |
| **æ€»è®¡** | **n_RBÃ—2 + 5** | **25ç»´ï¼ˆn_RB=10æ—¶ï¼‰** |

---

## 4. å®ç°ç»†èŠ‚

### 4.1 å…³é”®ä»£ç ç»“æ„

#### ä¸»è¦æ–‡ä»¶
- `main_PPO_AC.py`: ä¸»è®­ç»ƒå¾ªç¯
- `PPO_brain_AC.py`: PPOç®—æ³•å®ç°ï¼ˆæ”¯æŒGAT/MLPåˆ‡æ¢ï¼‰
- `Environment_marl_indoor.py`: å¤šUAVç¯å¢ƒ
- `arguments.py`: è¶…å‚æ•°é…ç½®

#### æ ¸å¿ƒåŠŸèƒ½

**1. GATç¼–ç å™¨**
```python
def multi_layer_gat(node_features, adj_matrix, ...):
    # å¤šå±‚GAT + æ®‹å·®è¿æ¥
    for layer in layers:
        x = graph_attention_layer(x, adj_matrix)
        x = x + residual  # æ®‹å·®è¿æ¥
    return x
```

**2. PPOè®­ç»ƒ**
```python
# GATæ¨¡å¼ï¼šèŠ‚ç‚¹çº§åˆ«çš„å€¼å‡½æ•°å’ŒåŠ¨ä½œåˆ†å¸ƒ
if use_gat:
    # é€‰æ‹©å¯¹åº”agentçš„èŠ‚ç‚¹è¾“å‡º
    power_prob = power_prob_all[:, agent_idx]
    v_pred = v_all[:, agent_idx]
```

**3. è”é‚¦å­¦ä¹ **
```python
def averaging_model():
    # å¹³å‡æ‰€æœ‰agentçš„å‚æ•°
    avg_params = mean([agent.params for agent in agents])
    for agent in agents:
        agent.params = avg_params
```

### 4.2 è®­ç»ƒæµç¨‹

```
1. åˆå§‹åŒ–ç¯å¢ƒï¼ˆéšæœºUAVä½ç½®ï¼‰
   â†“
2. æ¯ä¸ªæ—¶é—´æ­¥ï¼š
   - è·å–å›¾æ•°æ®ï¼ˆèŠ‚ç‚¹ç‰¹å¾ + é‚»æ¥çŸ©é˜µï¼‰
   - GATç¼–ç  â†’ Actorè¾“å‡ºåŠ¨ä½œ
   - ç¯å¢ƒæ‰§è¡Œ â†’ è·å¾—å¥–åŠ±
   â†“
3. è®¡ç®—GAEä¼˜åŠ¿
   â†“
4. é‡‡æ ·batchæ•°æ®
   â†“
5. å¯¹æ¯ä¸ªagentï¼š
   - é€‰æ‹©å¯¹åº”èŠ‚ç‚¹çš„è¾“å‡º
   - è®¡ç®—PPOæŸå¤±
   - æ›´æ–°ç½‘ç»œå‚æ•°
   â†“
6. è”é‚¦å­¦ä¹ ï¼šå¹³å‡æ‰€æœ‰agentå‚æ•°
   â†“
7. é‡å¤æ­¥éª¤2-6
```

---

## 5. å½“å‰è¿›å±•

### 5.1 å·²å®ŒæˆåŠŸèƒ½

âœ… **GATç½‘ç»œå®ç°**
- å¤šå±‚GATç¼–ç å™¨
- å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆ4ä¸ªå¤´ï¼‰
- æ®‹å·®è¿æ¥

âœ… **PPOç®—æ³•é›†æˆ**
- Actorï¼š3ä¸ªè¾“å‡ºå¤´ï¼ˆåŠŸç‡ã€RBã€å‹ç¼©æ¯”ï¼‰
- Criticï¼šèŠ‚ç‚¹çº§åˆ«çš„å€¼å‡½æ•°
- GAEä¼˜åŠ¿è®¡ç®—

âœ… **å¤šæ™ºèƒ½ä½“æ”¯æŒ**
- æ¯ä¸ªUAVç‹¬ç«‹ç½‘ç»œ
- å›¾æ•°æ®å…±äº«
- è”é‚¦å­¦ä¹ å‚æ•°èšåˆ

âœ… **æ•°å€¼ç¨³å®šæ€§ä¿®å¤**
- æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢NaNï¼‰
- Rewardå½’ä¸€åŒ–ä¿®å¤
- GAEè®¡ç®—ä¿®å¤

### 5.2 è®­ç»ƒçŠ¶æ€

**å½“å‰é—®é¢˜**ï¼š
- âŒ Actorå‚æ•°ï¼ˆmu, sigmaï¼‰å‡ºç°NaN
- âŒ Entropyä¸º0ï¼ˆåˆ†å¸ƒé€€åŒ–ï¼‰
- âŒ Policy Lossä¸º0ï¼ˆæ— æ¢¯åº¦ï¼‰

**å·²ä¿®å¤**ï¼š
- âœ… å€¼å‡½æ•°è¾“å‡ºæ­£å¸¸ï¼ˆéé›¶ï¼‰
- âœ… GAEè®¡ç®—æ­£ç¡®
- âœ… Rewardä¼ é€’æ­£å¸¸
- âœ… èŠ‚ç‚¹é€‰æ‹©é€»è¾‘ä¿®å¤

---

## 6. é‡åˆ°çš„é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 6.1 é—®é¢˜1ï¼šGAEè®¡ç®—é”™è¯¯

**é—®é¢˜**ï¼š
- GATæ¨¡å¼ä¸‹è¾“å…¥æ˜¯`[T, n_veh]`çš„2Dæ•°ç»„
- åŸ`get_gaes`å‡½æ•°åªèƒ½å¤„ç†1Dæ•°ç»„

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
def get_gaes(self, rewards, v_preds, v_preds_next):
    if len(rewards.shape) == 2:  # GATæ¨¡å¼
        # ä¸ºæ¯ä¸ªagentå•ç‹¬è®¡ç®—GAE
        for agent_idx in range(n_veh):
            gaes_agent = compute_gae(
                rewards[:, agent_idx],
                v_preds[:, agent_idx],
                v_preds_next[:, agent_idx]
            )
        return np.stack(gaes_list, axis=1)
```

### 6.2 é—®é¢˜2ï¼šRewardå½’ä¸€åŒ–å¯¼è‡´å…¨0

**é—®é¢˜**ï¼š
- æ‰€æœ‰rewardç›¸åŒï¼ˆå¦‚-1.0ï¼‰æ—¶ï¼Œå½’ä¸€åŒ–åå…¨éƒ¨å˜æˆ0
- å¯¼è‡´è®­ç»ƒä¿¡å·ä¸¢å¤±

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# åªåœ¨std > thresholdæ—¶å½’ä¸€åŒ–
if rewards_std > 1e-8:
    rewards = (rewards - rewards.mean()) / rewards_std
# å¦åˆ™ä¿æŒåŸå§‹å€¼
```

### 6.3 é—®é¢˜3ï¼šèŠ‚ç‚¹é€‰æ‹©é”™è¯¯

**é—®é¢˜**ï¼š
- è®­ç»ƒæ—¶å¯¹æ‰€æœ‰èŠ‚ç‚¹å–meanï¼Œå¯¼è‡´æ¢¯åº¦ä¿¡å·å¼±
- æ¯ä¸ªagentåº”è¯¥åªä½¿ç”¨è‡ªå·±çš„èŠ‚ç‚¹è¾“å‡º

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ·»åŠ agent_idxå‚æ•°
def train(..., agent_idx=0):
    # é€‰æ‹©å¯¹åº”agentçš„èŠ‚ç‚¹
    power_prob = power_prob_all[:, agent_idx]
    v_pred = v_all[:, agent_idx]
```

### 6.4 é—®é¢˜4ï¼šå‚æ•°NaN

**é—®é¢˜**ï¼š
- æ¢¯åº¦çˆ†ç‚¸å¯¼è‡´å‚æ•°å˜æˆNaN
- å€¼å‡½æ•°è¾“å‡ºå¼‚å¸¸

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ·»åŠ æ¢¯åº¦è£å‰ªï¼ˆclip_norm=0.5ï¼‰
- æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
- ä¿®å¤åˆå§‹åŒ–ï¼ˆbiasåˆå§‹åŒ–ï¼‰

---

## 7. ä¸‹ä¸€æ­¥è®¡åˆ’

### 7.1 çŸ­æœŸç›®æ ‡ï¼ˆ1-2å‘¨ï¼‰

**ä¼˜å…ˆçº§1ï¼šä¿®å¤Actor NaNé—®é¢˜**
- [ ] æ£€æŸ¥GATç¼–ç å™¨è¾“å‡ºæ˜¯å¦æ­£å¸¸
- [ ] æ£€æŸ¥Actorç½‘ç»œåˆå§‹åŒ–
- [ ] æ·»åŠ æ›´å¤šæ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
- [ ] éªŒè¯åˆ†å¸ƒå‚æ•°èŒƒå›´

**ä¼˜å…ˆçº§2ï¼šæ¢å¤è®­ç»ƒ**
- [ ] ç¡®ä¿æ‰€æœ‰Lossç»„ä»¶éé›¶
- [ ] éªŒè¯Entropyæ­£å¸¸
- [ ] æ£€æŸ¥æ¢¯åº¦æµ

### 7.2 ä¸­æœŸç›®æ ‡ï¼ˆ2-4å‘¨ï¼‰

**æ€§èƒ½ä¼˜åŒ–**
- [ ] è¶…å‚æ•°è°ƒä¼˜ï¼ˆå­¦ä¹ ç‡ã€ç†µæƒé‡ï¼‰
- [ ] ç½‘ç»œç»“æ„ä¼˜åŒ–ï¼ˆå±‚æ•°ã€éšè—ç»´åº¦ï¼‰
- [ ] æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›ï¼ˆè¾¹ç‰¹å¾ï¼‰

**åŠŸèƒ½æ‰©å±•**
- [ ] æ·»åŠ è¾¹ç‰¹å¾ï¼ˆEdge-GATï¼‰
- [ ] å®ç°é‚»å±…é‡‡æ ·ï¼ˆå¤§è§„æ¨¡æ‰©å±•ï¼‰
- [ ] å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆå‡†ç¡®åº¦ vs èƒ½æ•ˆï¼‰

### 7.3 é•¿æœŸç›®æ ‡ï¼ˆ1-2æœˆï¼‰

**ç®—æ³•æ”¹è¿›**
- [ ] å¯¹æ¯”å®éªŒï¼ˆGAT vs MLPï¼‰
- [ ] æ¶ˆèå®éªŒï¼ˆæ®‹å·®è¿æ¥ã€æ³¨æ„åŠ›å¤´æ•°ï¼‰
- [ ] ä¸å…¶ä»–GNNæ–¹æ³•å¯¹æ¯”ï¼ˆGraphSAGEã€GCNï¼‰

**åº”ç”¨æ‰©å±•**
- [ ] æ‰©å±•åˆ°æ›´å¤šUAVï¼ˆ10+ï¼‰
- [ ] åŠ¨æ€ç¯å¢ƒï¼ˆç§»åŠ¨UAVï¼‰
- [ ] å®é™…éƒ¨ç½²æµ‹è¯•

---

## 8. æŠ€æœ¯äº®ç‚¹

### 8.1 åˆ›æ–°ç‚¹

1. **å›¾æ³¨æ„åŠ›ç½‘ç»œ + å¤šæ™ºèƒ½ä½“PPO**
   - æ˜¾å¼å»ºæ¨¡UAVé€šä¿¡å…³ç³»
   - å¤šå¤´æ³¨æ„åŠ›æ•æ‰å¤æ‚äº¤äº’

2. **èŠ‚ç‚¹çº§åˆ«çš„å€¼å‡½æ•°**
   - æ¯ä¸ªUAVç‹¬ç«‹å€¼ä¼°è®¡
   - æ›´å¥½çš„å¤šæ™ºèƒ½ä½“åä½œ

3. **è¯­ä¹‰é€šä¿¡ä¼˜åŒ–**
   - åŒæ—¶ä¼˜åŒ–RBã€åŠŸç‡ã€å‹ç¼©æ¯”
   - è¯­ä¹‰èƒ½æ•ˆæœ€å¤§åŒ–

### 8.2 æŠ€æœ¯éš¾ç‚¹

1. **å½¢çŠ¶åŒ¹é…**
   - GATè¾“å‡º`[batch*n_veh, ...]`
   - è®­ç»ƒæ—¶éœ€è¦é€‰æ‹©å¯¹åº”èŠ‚ç‚¹

2. **æ•°å€¼ç¨³å®šæ€§**
   - å¤šæ™ºèƒ½ä½“è®­ç»ƒå®¹æ˜“ä¸ç¨³å®š
   - éœ€è¦æ¢¯åº¦è£å‰ªå’Œæ•°å€¼æ£€æŸ¥

3. **è”é‚¦å­¦ä¹ **
   - å‚æ•°èšåˆç­–ç•¥
   - ä¿æŒè®­ç»ƒä¸€è‡´æ€§

---

## 9. å®éªŒè®¾ç½®

### 9.1 ç¯å¢ƒå‚æ•°

| å‚æ•° | å€¼ |
|------|-----|
| UAVæ•°é‡ | 6 |
| RBæ•°é‡ | 10 |
| åŒºåŸŸå¤§å° | 25m Ã— 25m |
| UAVé«˜åº¦ | 1.5m |
| é€šä¿¡èŒƒå›´ | 500m |

### 9.2 ç½‘ç»œå‚æ•°

| å‚æ•° | å€¼ |
|------|-----|
| GATå±‚æ•° | 3 |
| éšè—ç»´åº¦ | [128, 128, 128] |
| æ³¨æ„åŠ›å¤´æ•° | 4 |
| å­¦ä¹ ç‡ | 1e-6 |
| ç†µæƒé‡ | 0.01 |

### 9.3 è®­ç»ƒå‚æ•°

| å‚æ•° | å€¼ |
|------|-----|
| Episodeæ•° | 1000 |
| æ—¶é—´æ­¥æ•° | 100 |
| Batchå¤§å° | 512 |
| PPOæ›´æ–°æ¬¡æ•° | 32 |
| è”é‚¦å­¦ä¹ é¢‘ç‡ | æ¯episode |

---

## 10. æ€»ç»“

### 10.1 å·²å®Œæˆ

- âœ… GATç½‘ç»œæ¶æ„å®ç°
- âœ… å¤šæ™ºèƒ½ä½“PPOé›†æˆ
- âœ… è¯­ä¹‰é€šä¿¡æ”¯æŒ
- âœ… æ•°å€¼ç¨³å®šæ€§ä¿®å¤

### 10.2 è¿›è¡Œä¸­

- ğŸ”„ Actor NaNé—®é¢˜è°ƒè¯•
- ğŸ”„ è®­ç»ƒæµç¨‹éªŒè¯
- ğŸ”„ æ€§èƒ½ä¼˜åŒ–

### 10.3 é¢„æœŸæˆæœ

- ğŸ“Š è®­ç»ƒæ›²çº¿æ”¶æ•›
- ğŸ“ˆ æ€§èƒ½æå‡ï¼ˆvs MLP baselineï¼‰
- ğŸ“ è®ºæ–‡æ’°å†™å‡†å¤‡

---

## è°¢è°¢ï¼

### è”ç³»æ–¹å¼
- é¡¹ç›®ä»£ç ï¼š`/home/qiankun/GAT_RA`
- ä¸»è¦æ–‡ä»¶ï¼š
  - `main_PPO_AC.py`
  - `PPO_brain_AC.py`
  - `Environment_marl_indoor.py`

### å‚è€ƒæ–‡çŒ®
- Graph Attention Networks (VeliÄkoviÄ‡ et al., 2018)
- Proximal Policy Optimization (Schulman et al., 2017)
- Multi-Agent Reinforcement Learning

---

## é™„å½•ï¼šå…³é”®ä»£ç ç‰‡æ®µ

### GATç¼–ç å™¨
```python
def multi_layer_gat(node_features, adj_matrix, ...):
    x = node_features
    for i, hidden_dim in enumerate(hidden_dims):
        x_input = x  # æ®‹å·®è¿æ¥
        x = graph_attention_layer(x, adj_matrix, ...)
        if use_residual and i > 0:
            x = x + x_input  # æ®‹å·®
    return x
```

### PPOæŸå¤±è®¡ç®—
```python
# Policy Loss
ratio = new_prob / old_prob
L_clip = min(ratio * GAE, clip(ratio) * GAE)

# Value Loss
L_vf = (reward + Î³ * v_next - v_pred)Â²

# Entropy
S = entropy(power_dist) + entropy(RB_dist) + entropy(rho_dist)

# Total Loss
L = L_clip + L_RB + L_rho - c1 * L_vf + c2 * S
```

---

**æ±‡æŠ¥ç»“æŸï¼Œæ¬¢è¿æé—®ï¼**
