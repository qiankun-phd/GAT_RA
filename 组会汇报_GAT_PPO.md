# 基于图注意力网络的多智能体强化学习
## 无人机网络资源分配与语义通信优化

**汇报人**: [姓名]  
**日期**: 2024年1月  
**研究方向**: 多智能体强化学习 | 图神经网络 | 语义通信

---

## 📑 目录

1. **研究背景与动机**
2. **问题定义**
3. **方法介绍**
4. **系统架构**
5. **实现细节**
6. **当前进展**
7. **遇到的问题**
8. **下一步计划**

---

## 1. 研究背景与动机

### 1.1 研究背景

- **多无人机网络**已成为未来通信系统的重要组成部分
- **资源分配**是多无人机网络的核心挑战
  - 有限的频谱资源
  - 动态的信道条件
  - 多智能体协作与竞争

### 1.2 语义通信

- **传统通信**: 传输原始数据比特
- **语义通信**: 传输语义信息，提高通信效率
- **关键参数**: 
  - 语义准确度 (Semantic Accuracy)
  - 语义能量效率 (Semantic-EE)
  - 压缩比 (Compression Ratio, ρ)

### 1.3 研究动机

- **现有方法局限**:
  - MLP无法有效建模智能体间的交互关系
  - 缺乏对图结构的显式建模
- **GAT的优势**:
  - 显式建模智能体间的通信关系
  - 注意力机制捕捉重要邻居信息
  - 更好的协作能力

---

## 2. 问题定义

### 2.1 场景设置

```
┌─────────────────────────────────────┐
│  室内环境 (25m × 25m × 1.5m)       │
│                                     │
│  • 6个UAV                           │
│  • 10个资源块 (RB)                  │
│  • 1个地面基站 (GBS)                │
│                                     │
│  每个UAV需要决策:                   │
│  1. 选择哪个RB                      │
│  2. 传输功率 (dB)                   │
│  3. 语义压缩比 (ρ ∈ [0,1])         │
└─────────────────────────────────────┘
```

### 2.2 优化目标

**最大化语义能量效率 (Semantic-EE)**

```
Semantic-EE = Semantic_Accuracy / Total_Power
```

其中：
- `Semantic_Accuracy = A_max × (1 - exp(-β×ρ)) × log(1+SINR) / log(1+max_SINR)`
- `Total_Power = Circuit_Power + Transmit_Power`

### 2.3 约束条件

- **SINR阈值**: 传输成功的SINR ≥ 2.5 dB
- **资源冲突**: 同一RB不能同时被多个UAV使用
- **功率限制**: 传输功率在合理范围内

---

## 3. 方法介绍

### 3.1 整体框架

```
┌─────────────────────────────────────────────┐
│        多智能体近端策略优化 (MAPPO)         │
│                                             │
│  ┌──────────────┐      ┌──────────────┐   │
│  │  GAT编码器   │  →   │  Actor网络   │   │
│  │  (图结构)    │      │  (策略)      │   │
│  └──────────────┘      └──────────────┘   │
│         ↓                      ↓            │
│  ┌──────────────┐      ┌──────────────┐   │
│  │ 节点嵌入     │      │  动作输出    │   │
│  │ [n_veh, dim] │      │ [RB,P,ρ]     │   │
│  └──────────────┘      └──────────────┘   │
│         ↓                                   │
│  ┌──────────────┐                          │
│  │  Critic网络  │                          │
│  │  (值函数)    │                          │
│  └──────────────┘                          │
└─────────────────────────────────────────────┘
```

### 3.2 图注意力网络 (GAT)

#### 节点特征
- CSI快衰落: `[n_RB]`
- CSI慢衰落: `[n_RB]`
- 位置信息: `[x, y, z]`
- 成功标志: `[1]`
- Episode进度: `[1]`
- **总维度**: `n_RB × 2 + 3 + 2 = 35` (n_RB=10时)

#### 邻接矩阵
- 基于通信距离构建
- 如果 `distance < comm_range` (500m)，则连接
- 对称矩阵，表示UAV间的通信关系

#### 注意力机制
```
e_ij = LeakyReLU(W_a^T [W_h h_i || W_h h_j])
α_ij = softmax_j(e_ij)
h_i' = σ(Σ_j α_ij W_h h_j)
```

#### 多头注意力
- 默认4个头，学习不同的关系模式
- 输出拼接: `[n_veh, hidden_dim × num_heads]`

### 3.3 PPO算法

#### 损失函数
```
L = L_clip_power + L_clip_RB + L_clip_rho - c1 × L_vf + c2 × S
```

- **L_clip**: PPO裁剪损失，防止策略更新过大
- **L_vf**: 值函数损失 (MSE)
- **S**: 策略熵 (鼓励探索)

#### GAE (Generalized Advantage Estimation)
```
δ_t = r_t + γ × V(s_{t+1}) - V(s_t)
GAE_t = δ_t + (γλ) × GAE_{t+1}
```

---

## 4. 系统架构

### 4.1 代码结构

```
GAT_RA/
├── main_PPO_AC.py              # 主训练循环
├── PPO_brain_AC.py             # PPO智能体 (GAT+PPO)
├── Environment_marl_indoor.py  # 环境模拟
├── arguments.py                # 参数配置
└── logs/                       # 训练日志
```

### 4.2 训练流程

```
1. 初始化环境
   ↓
2. 每个Episode:
   ├─ 重置UAV位置
   ├─ 更新信道状态
   ├─ 收集轨迹数据 (T_TIMESTEPS步)
   │   ├─ GAT编码状态
   │   ├─ Actor选择动作
   │   ├─ 环境执行动作
   │   └─ 计算奖励
   └─ 计算GAE
   ↓
3. 采样批次数据
   ↓
4. 训练每个Agent的PPO网络
   ↓
5. 联邦学习聚合 (每meta_episode次)
   └─ 平均所有Agent的参数
```

### 4.3 网络架构

#### GAT编码器
```
输入: [batch, n_veh, node_feature_dim]
  ↓
GAT Layer 1: [n_veh, hidden_1] × num_heads
  ↓ (残差连接)
GAT Layer 2: [n_veh, hidden_2] × num_heads
  ↓ (残差连接)
GAT Layer 3: [n_veh, hidden_3] × num_heads
  ↓
节点嵌入: [batch, n_veh, hidden_3 × num_heads]
```

#### Actor网络
```
节点嵌入 → 投影层 → Actor Head
  ├─ Power Head (Normal分布)
  ├─ RB Head (Categorical分布)
  └─ Rho Head (Beta分布)
```

#### Critic网络
```
节点嵌入 → 投影层 → 值函数输出
输出: [batch, n_veh] (每个节点一个值)
```

---

## 5. 实现细节

### 5.1 关键技术点

#### ✅ 已完成

1. **GAT编码器实现**
   - 多层图注意力网络
   - 残差连接 (提升稳定性)
   - 多头注意力机制

2. **节点级别值函数**
   - 每个UAV有独立的值估计
   - 输出形状: `[batch, n_veh]`

3. **多动作空间支持**
   - 离散动作 (RB选择)
   - 连续动作 (功率、压缩比)
   - Beta分布用于压缩比

4. **GAE计算修复**
   - 支持2D输入 `[T, n_veh]`
   - 为每个agent单独计算GAE

5. **联邦学习聚合**
   - GAT模式: 自动聚合所有参数
   - MLP模式: 手动聚合关键参数

### 5.2 代码特性

- **双模式支持**: GAT模式 / MLP模式 (向后兼容)
- **模块化设计**: 易于扩展和维护
- **调试友好**: 详细的调试输出

---

## 6. 当前进展

### 6.1 已完成工作

| 模块 | 状态 | 说明 |
|------|------|------|
| GAT编码器 | ✅ | 多层GAT + 残差连接 |
| Actor网络 | ✅ | 支持3个动作头 |
| Critic网络 | ✅ | 节点级别值函数 |
| GAE计算 | ✅ | 支持多智能体 |
| 联邦学习 | ✅ | 参数聚合机制 |
| 环境集成 | ✅ | 语义通信计算 |

### 6.2 训练状态

- **MLP模式**: ✅ 正常工作，可以收敛
- **GAT模式**: ⚠️ 正在调试中

### 6.3 性能指标

- **环境指标**:
  - SINR范围: ~35 dB (平均)
  - 阈值通过率: 100%
  - Semantic-EE范围: 0.001-0.01

---

## 7. 遇到的问题

### 7.1 主要问题

#### ❌ GAT模式训练问题

**症状**:
- Loss始终为0.0
- Success Rate为0%
- Reward为-1.0 (所有UAV失败)
- Actor参数 (mu, sigma) 出现NaN

**已修复**:
- ✅ GAE计算 (支持2D输入)
- ✅ Reward normalize (避免除零)
- ✅ 值函数输出 (非零值)
- ✅ 梯度裁剪 (防止NaN)
- ✅ 节点选择逻辑 (不再对所有节点取mean)

**待解决**:
- ⚠️ Actor参数NaN问题
- ⚠️ Entropy为0
- ⚠️ Policy Loss为0

### 7.2 问题分析

#### 可能原因

1. **GAT编码器输出问题**
   - 编码器可能输出全0或NaN
   - 需要检查GAT层的输出

2. **形状不匹配**
   - Actor输入形状可能不正确
   - 需要验证数据流

3. **初始化问题**
   - 网络参数初始化可能有问题
   - 需要检查初始化方法

4. **数值稳定性**
   - 梯度爆炸导致NaN
   - 需要更强的梯度裁剪

### 7.3 调试策略

1. **添加调试输出**
   - 检查GAT编码器输出
   - 检查Actor分布参数
   - 检查梯度值

2. **对比MLP模式**
   - 验证数据流是否正确
   - 对比网络输出

3. **逐步验证**
   - 先验证GAT编码器
   - 再验证Actor网络
   - 最后验证完整训练流程

---

## 8. 下一步计划

### 8.1 短期目标 (1-2周)

#### 🔴 高优先级

1. **修复GAT模式训练**
   - 解决Actor参数NaN问题
   - 恢复Policy Loss计算
   - 确保训练可以正常进行

2. **验证训练效果**
   - 对比GAT vs MLP性能
   - 验证GAT是否带来提升

#### 🟡 中优先级

3. **优化训练稳定性**
   - 调整学习率
   - 优化梯度裁剪
   - 改进初始化方法

4. **完善调试工具**
   - 添加更多诊断信息
   - 可视化训练过程

### 8.2 中期目标 (1个月)

1. **性能优化**
   - 提升训练效率
   - 优化内存使用

2. **功能扩展**
   - 考虑引入边特征 (Edge-GAT)
   - 支持动态图结构

3. **实验对比**
   - 与baseline方法对比
   - 不同场景下的性能评估

### 8.3 长期目标 (3个月)

1. **理论分析**
   - GAT在多智能体场景下的理论保证
   - 收敛性分析

2. **应用拓展**
   - 扩展到更大规模网络
   - 考虑更复杂的场景

---

## 9. 技术亮点

### 9.1 创新点

1. **GAT + PPO结合**
   - 首次在多无人机资源分配中应用GAT
   - 显式建模智能体间关系

2. **语义通信优化**
   - 同时优化资源分配和语义压缩
   - 多目标优化框架

3. **节点级别值函数**
   - 每个智能体独立的值估计
   - 更适合多智能体场景

### 9.2 参考实现

- **Edge-GAT**: 残差连接、边特征
- **GraphSAGE**: 邻居采样、多种聚合方式

---

## 10. 总结

### 10.1 已完成

- ✅ GAT编码器实现
- ✅ PPO算法集成
- ✅ 多动作空间支持
- ✅ 联邦学习机制
- ✅ MLP模式正常工作

### 10.2 进行中

- 🔄 GAT模式调试
- 🔄 训练稳定性优化

### 10.3 预期成果

- 验证GAT在多智能体场景下的有效性
- 提升资源分配性能
- 优化语义通信效率

---

## 附录

### A. 关键参数

| 参数 | 值 | 说明 |
|------|-----|------|
| n_veh | 6 | UAV数量 |
| n_RB | 10 | 资源块数量 |
| lr_main | 1e-6 | 主学习率 |
| weight_for_entropy | 0.01 | 熵权重 |
| num_gat_heads | 4 | GAT注意力头数 |
| hidden_dims | [128, 256, 512] | GAT隐藏层维度 |

### B. 文件说明

- `main_PPO_AC.py`: 主训练脚本
- `PPO_brain_AC.py`: PPO智能体实现
- `Environment_marl_indoor.py`: 环境模拟
- `arguments.py`: 命令行参数

### C. 运行命令

```bash
# MLP模式
python main_PPO_AC.py --n_episode 1000 --n_veh 6 --n_RB 10 \
    --optimization_target EE --Do_FL

# GAT模式
python main_PPO_AC.py --n_episode 1000 --n_veh 6 --n_RB 10 \
    --optimization_target EE --Do_FL --use_gat
```

---

## 谢谢！

**Q&A**

---

## 备用幻灯片

### 技术细节补充

#### GAT层实现
```python
def graph_attention_layer(node_features, adj_matrix, num_heads, out_dim):
    # 计算注意力权重
    e_ij = compute_attention_scores(node_features)
    α_ij = softmax(e_ij, adj_matrix)
    # 聚合邻居信息
    h_i' = aggregate_neighbors(node_features, α_ij)
    return h_i'
```

#### PPO损失计算
```python
ratio = new_prob / old_prob
L_clip = min(ratio * GAE, clip(ratio, 1-ε, 1+ε) * GAE)
L = L_clip - c1 * L_vf + c2 * S
```

#### 语义准确度计算
```python
A = A_max * (1 - exp(-β * ρ)) * log(1 + SINR) / log(1 + max_SINR)
Semantic_EE = A / Total_Power
```

---

**汇报结束**

